{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 32, 50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w = np.array([1,2,3])\n",
    "X = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "w@X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([1,2,3])\n",
    "w.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,d,k,sigma = 500,1000,100,1\n",
    "\n",
    "# generate normal distributed data\n",
    "X = np.random.normal(0.5, 2, (n,d)) #generate my own X (nxd) with random distribution\n",
    "w_data = np.zeros(d) # given w to generate y\n",
    "for j in range(k):\n",
    "    w_data[j] = j/k\n",
    "\n",
    "# standardize X\n",
    "mean = np.mean(X,axis=0)\n",
    "std = np.std(X,axis=0)\n",
    "X_zscored = np.zeros((n,d))\n",
    "for i in range(d):\n",
    "    X_zscored[:,i] = (X[:,i] - mean[i])/std[i]\n",
    "\n",
    "noise = np.random.normal(0, sigma, 500) # generate noise, bias = 0\n",
    "y = X_zscored@w_data + noise # generate y = wx + noise\n",
    "\n",
    "n,d = X_zscored.shape\n",
    "w = w_data\n",
    "b = (1/n)*(np.sum(y - X_zscored@w))# calculate bias\n",
    "(X_zscored@w).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.zeros(d) #scalar\n",
    "w = np.zeros(d) #scalar\n",
    "_lambda = 0.01\n",
    "a = 2*(np.linalg.norm(X, axis = 0)**2)\n",
    "for k in range(d):\n",
    "    WX = np.zeros(n)\n",
    "    ybWX = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        w_ = w\n",
    "        w_[k] = 0 #zero at the kth entry\n",
    "        WX[i] = np.dot(w_,X[i,:])\n",
    "        ybWX[i] = y[i] - (b + WX[i])\n",
    "    c[k] = 2* np.dot(X[:,k],ybWX) #inner product\n",
    "    \n",
    "    if c[k] < -_lambda:\n",
    "        w[k] = (c[k] + _lambda)/a[k]\n",
    "    elif c[k] > _lambda:\n",
    "        w[k] = (c[k] - _lambda)/a[k]\n",
    "    else:\n",
    "        w[k] = 0\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2576.3321817823366"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,d,k,sigma = 500,1000,100,1\n",
    "\n",
    "# generate normal distributed data\n",
    "X = np.random.normal(0.5, 2, (n,d)) #generate my own X (nxd) with random distribution\n",
    "w_data = np.zeros(d) # given w to generate y\n",
    "for j in range(k):\n",
    "    w_data[j] = j/k\n",
    "\n",
    "# standardize X\n",
    "mean = np.mean(X,axis=0)\n",
    "std = np.std(X,axis=0)\n",
    "X_zscored = np.zeros((n,d))\n",
    "for i in range(d):\n",
    "    X_zscored[:,i] = (X[:,i] - mean[i])/std[i]\n",
    "\n",
    "noise = np.random.normal(0, sigma, 500) # generate noise, bias = 0\n",
    "y = X_zscored@w_data + noise # generate y = wx + noise\n",
    "\n",
    "# choose the first lambda\n",
    "y_mean = np.mean(y)\n",
    "l = np.zeros(d)\n",
    "for k in range(d):\n",
    "    l[k] = 2*abs(np.dot(X[:,k],y-y_mean))\n",
    "lambda_max = np.max(l)\n",
    "lambda_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7630cac1be2ce353e8b9db6b173bfb313a38b5a49c89b23e86948b2ee501bfa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
